import pandas as pd
from urllib.parse import urlparse

# 1Ô∏è‚É£ Carrega o ficheiro CSV com todos os links
df = pd.read_csv("../data/isel_links_hierarquico.csv")

# 2Ô∏è‚É£ Normaliza e separa cada URL em partes
def extract_path_parts(url):
    path = urlparse(url).path.strip("/")
    parts = [p for p in path.split("/") if p and p not in ("pt", "en")]
    return parts

rows = []
for url in df["URL"]:
    parts = extract_path_parts(url)
    row = {"URL": url}
    for i, p in enumerate(parts, start=1):
        row[f"N√≠vel {i}"] = p
    rows.append(row)

# 3Ô∏è‚É£ Cria novo DataFrame com colunas flex√≠veis
df_hier = pd.DataFrame(rows)

# Ajusta nomes das colunas para serem mais "sem√¢nticas"
max_depth = len([c for c in df_hier.columns if c.startswith("N√≠vel")])

col_names = ["Grupo", "Subgrupo", "Sub-subgrupo", "Sub-sub-subgrupo", "Sub-sub-sub-subgrupo"]
# corta ou expande conforme a profundidade encontrada
rename_map = {f"N√≠vel {i+1}": (col_names[i] if i < len(col_names) else f"N√≠vel {i+1}") for i in range(max_depth)}
df_hier.rename(columns=rename_map, inplace=True)

# 4Ô∏è‚É£ Ordena pela hierarquia (para ficar agrupado no Excel)
sort_cols = [c for c in df_hier.columns if c != "URL"]
df_hier = df_hier.sort_values(by=sort_cols, na_position="last")

# 5Ô∏è‚É£ Exporta para Excel (melhor que CSV neste caso)
output_file = "../data/isel_site_tree.xlsx"
df_hier.to_excel(output_file, index=False, engine="openpyxl")

print(f"‚úÖ Hierarquia criada com sucesso!")
print(f"üìÅ Ficheiro: {output_file}")
print(f"üìä Total de linhas: {len(df_hier)}")
